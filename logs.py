import streamlit as st
import pandas as pd
import re
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# Configura√ß√£o da p√°gina
st.set_page_config(page_title="System Event Prediction App", layout="wide")
st.title("üöÄ System Event Prediction Using Transformers")

# Fun√ß√£o para parse dos logs
def parse_log(log_entry):
    """
    Extrai informa√ß√µes de um log do sistema Linux.
    Exemplo de log esperado:
    'Jun 14 15:16:01 combo sshd[19939]: authentication failure; ...'
    """
    pattern = (
        r"(?P<timestamp>\w{3}\s+\d{1,2}\s+\d{2}:\d{2}:\d{2})\s+"
        r"(?P<hostname>\S+)\s+"
        r"(?P<process>\S+)\[\d+\]:\s+"
        r"(?P<event>.+)"
    )
    match = re.match(pattern, log_entry)
    if match:
        return match.groupdict()
    else:
        return {
            "timestamp": None,
            "hostname": None,
            "process": None,
            "event": log_entry.strip()
        }

# Fun√ß√£o para converter string de timestamp em datetime (assumindo ano corrente)
def convert_timestamp(ts_str):
    try:
        # Usamos o ano atual para compor o datetime
        current_year = datetime.now().year
        return datetime.strptime(f"{ts_str} {current_year}", "%b %d %H:%M:%S %Y")
    except Exception:
        return None

# Se√ß√£o 1: Upload de Arquivo
st.header("1. Carregar e Analisar Logs")
uploaded_file = st.file_uploader("üìÅ Fa√ßa upload do arquivo de logs (.log ou .csv)", type=["log", "csv"])

if uploaded_file:
    try:
        # Leitura do arquivo
        log_lines = uploaded_file.getvalue().decode("utf-8").splitlines()
        st.success("‚úÖ Arquivo carregado com sucesso!")

        # Cria√ß√£o do DataFrame inicial
        df_logs = pd.DataFrame({"log_entry": log_lines})
        st.subheader("Visualiza√ß√£o dos Logs Carregados")
        st.dataframe(df_logs.head())

        # Parse dos logs para extrair informa√ß√µes estruturadas
        parsed_logs = df_logs["log_entry"].apply(parse_log).apply(pd.Series)
        # Converter timestamp
        parsed_logs["timestamp"] = parsed_logs["timestamp"].apply(convert_timestamp)

        st.subheader("Logs Estruturados")
        st.dataframe(parsed_logs.head())

        # Exibi√ß√£o de estat√≠sticas b√°sicas
        st.subheader("Estat√≠sticas B√°sicas dos Logs")
        total_logs = len(parsed_logs)
        unique_processes = parsed_logs["process"].nunique()
        unique_events = parsed_logs["event"].nunique()
        unique_hosts = parsed_logs["hostname"].nunique()

        col1, col2, col3, col4 = st.columns(4)
        col1.metric("Total de Logs", total_logs)
        col2.metric("Processos √önicos", unique_processes)
        col3.metric("Eventos √önicos", unique_events)
        col4.metric("Hosts √önicos", unique_hosts)

        # Exemplo de gr√°fico: frequ√™ncia de eventos ao longo do tempo
        st.subheader("Frequ√™ncia de Logs ao Longo do Tempo")
        # Remover registros sem timestamp v√°lido
        valid_logs = parsed_logs.dropna(subset=["timestamp"])
        valid_logs["hora"] = valid_logs["timestamp"].dt.hour
        freq_por_hora = valid_logs["hora"].value_counts().sort_index()

        fig, ax = plt.subplots(figsize=(10, 5))
        sns.lineplot(x=freq_por_hora.index, y=freq_por_hora.values, marker="o", ax=ax)
        ax.set_xlabel("Hora do Dia")
        ax.set_ylabel("N√∫mero de Logs")
        ax.set_title("Logs por Hora")
        st.pyplot(fig)

    except Exception as e:
        st.error(f"Erro ao processar o arquivo: {e}")
else:
    st.info("Aguardando upload do arquivo de logs...")
